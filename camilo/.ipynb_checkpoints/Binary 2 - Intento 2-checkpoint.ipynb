{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"./data/train/databinarystudents_train.csv\")\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"./data/test/databinarystudents_test.csv\")\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer=train.drop(['id','yL','x3','x4','x5','x6','x7','x13','x14','x15','x16',\n",
    "                  'x17','x18','x19','x20','x28','x29'], axis=1) #no tuve en cuenta conteos X25, X26 ni X30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe con variables numéricas normalizadas\n",
    "# Normalización = ( x – min(x) ) / ( max(x) – min(x) )\n",
    "col_names = numer.columns.values.tolist()\n",
    "scaler = MinMaxScaler()\n",
    "numern = scaler.fit_transform(numer)\n",
    "numern = pd.DataFrame(numern, columns=col_names)\n",
    "numern.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train.filter(['yL','x3','x4','x5','x6','x7','x13','x14','x15','x16',\n",
    "                  'x17','x18','x19','x20','x28','x29'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.concat([X,numern], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yL</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>x16</th>\n",
       "      <th>...</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x30</th>\n",
       "      <th>x31</th>\n",
       "      <th>x32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976564</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.040829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069157</td>\n",
       "      <td>0.092288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302739</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.422450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.080836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989137</td>\n",
       "      <td>0.887578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.970630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.111743</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.086533</td>\n",
       "      <td>0.113951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.146081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.186989</td>\n",
       "      <td>0.243571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.493906</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.471802</td>\n",
       "      <td>0.621287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    yL   x3   x4   x5   x6   x7  x13  x14  x15  x16  ...       x21       x22  \\\n",
       "0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  ...  0.000000  0.000000   \n",
       "1  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.302739  0.000127   \n",
       "2  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.004751  0.000000   \n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.938542  0.000000   \n",
       "4  1.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  ...  0.811079  0.000000   \n",
       "\n",
       "        x23       x24   x25   x26       x27       x30       x31       x32  \n",
       "0  0.976564  0.000354  0.50  0.75  0.040829  1.000000  0.069157  0.092288  \n",
       "1  0.422450  0.000000  1.00  0.25  0.080836  1.000000  0.989137  0.887578  \n",
       "2  0.970630  0.000000  0.50  0.75  0.111743  0.500000  0.086533  0.113951  \n",
       "3  0.009153  0.000118  0.50  0.25  0.146081  1.000000  0.186989  0.243571  \n",
       "4  0.005130  0.000000  0.25  1.00  0.493906  0.333333  0.471802  0.621287  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detección de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1     0.325064\n",
      "x2     0.395624\n",
      "x8     0.238772\n",
      "x9     0.322222\n",
      "x10    0.023814\n",
      "x11    0.402772\n",
      "x12    0.223132\n",
      "x21    0.812721\n",
      "x22    0.000633\n",
      "x23    0.455643\n",
      "x24    0.001801\n",
      "x25    0.250000\n",
      "x26    0.250000\n",
      "x27    0.183854\n",
      "x30    0.666667\n",
      "x31    0.608135\n",
      "x32    0.642800\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "Q1 = numern.quantile(0.25)\n",
    "Q3 = numern.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numern_out = numern[~((numern < (Q1 - 1.5 * IQR)) |(numern > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "numern_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.iloc[list(numern_out.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.concat([X,numern_out], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54, 32), (54,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=train.drop(['yL'], axis=1)\n",
    "Y_train=train['yL']\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x31</td>\n",
       "      <td>x32</td>\n",
       "      <td>0.976208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x32</td>\n",
       "      <td>x31</td>\n",
       "      <td>0.976208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x2</td>\n",
       "      <td>x1</td>\n",
       "      <td>0.949355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x1</td>\n",
       "      <td>x2</td>\n",
       "      <td>0.949355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x21</td>\n",
       "      <td>x23</td>\n",
       "      <td>0.895835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature1 feature2      corr\n",
       "0      x31      x32  0.976208\n",
       "1      x32      x31  0.976208\n",
       "2       x2       x1  0.949355\n",
       "3       x1       x2  0.949355\n",
       "4      x21      x23  0.895835"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a dataframe with the correlation between features\n",
    "# remember that the absolute value of the correlation\n",
    "# coefficient is important and not the sign\n",
    "\n",
    "corrmat = X_train.corr()\n",
    "corrmat = corrmat.abs().unstack() # absolute value of corr coef\n",
    "corrmat = corrmat.sort_values(ascending=False)\n",
    "corrmat = corrmat[corrmat >= 0.8]\n",
    "corrmat = corrmat[corrmat < 1]\n",
    "corrmat = pd.DataFrame(corrmat).reset_index()\n",
    "corrmat.columns = ['feature1', 'feature2', 'corr']\n",
    "corrmat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 3 correlated groups\n",
      "out of 32 total features\n"
     ]
    }
   ],
   "source": [
    "# find groups of correlated features\n",
    "\n",
    "grouped_feature_ls = []\n",
    "correlated_groups = []\n",
    "\n",
    "for feature in corrmat.feature1.unique():\n",
    "    if feature not in grouped_feature_ls:\n",
    "\n",
    "        # find all features correlated to a single feature\n",
    "        correlated_block = corrmat[corrmat.feature1 == feature]\n",
    "        grouped_feature_ls = grouped_feature_ls + list(\n",
    "            correlated_block.feature2.unique()) + [feature]\n",
    "\n",
    "        # append the block of features to the list\n",
    "        correlated_groups.append(correlated_block)\n",
    "\n",
    "print('found {} correlated groups'.format(len(correlated_groups)))\n",
    "print('out of {} total features'.format(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  feature1 feature2      corr\n",
      "0      x31      x32  0.976208\n",
      "\n",
      "  feature1 feature2      corr\n",
      "2       x2       x1  0.949355\n",
      "9       x2      x11  0.809755\n",
      "\n",
      "  feature1 feature2      corr\n",
      "4      x21      x23  0.895835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now we can visualise each group. We see that some groups contain\n",
    "# only 2 correlated features, some other groups present several features \n",
    "# that are correlated among themselves.\n",
    "\n",
    "for group in correlated_groups:\n",
    "    print(group)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x31</td>\n",
       "      <td>x32</td>\n",
       "      <td>0.976208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature1 feature2      corr\n",
       "0      x31      x32  0.976208"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can now investigate further features within one group.\n",
    "# let's for example select group 1\n",
    "\n",
    "group1 = correlated_groups[0]\n",
    "group1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# we could select the features with less missing data\n",
    "# like this:\n",
    "\n",
    "for feature in list(group1.feature2.unique())+['x31']:\n",
    "    print(X_train[feature].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=39, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(group1.feature2.unique())+['x31']\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "rf.fit(X_train[features].fillna(0), Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x32</td>\n",
       "      <td>0.505996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x31</td>\n",
       "      <td>0.494004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature  importance\n",
       "0     x32    0.505996\n",
       "1     x31    0.494004"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we get the feature importance attributed by the \n",
    "# random forest model (more on this in coming lectures)\n",
    "\n",
    "importance = pd.concat(\n",
    "    [pd.Series(features),\n",
    "     pd.Series(rf.feature_importances_)], axis=1)\n",
    "\n",
    "importance.columns = ['feature', 'importance']\n",
    "importance.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x2</td>\n",
       "      <td>x1</td>\n",
       "      <td>0.949355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>x2</td>\n",
       "      <td>x11</td>\n",
       "      <td>0.809755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature1 feature2      corr\n",
       "2       x2       x1  0.949355\n",
       "9       x2      x11  0.809755"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can now investigate further features within one group.\n",
    "# let's for example select group 2\n",
    "\n",
    "group2 = correlated_groups[1]\n",
    "group2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# we could select the features with less missing data\n",
    "# like this:\n",
    "\n",
    "for feature in list(group2.feature2.unique())+['x2']:\n",
    "    print(X_train[feature].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=39, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(group2.feature2.unique())+['x2']\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "rf.fit(X_train[features].fillna(0), Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x11</td>\n",
       "      <td>0.352549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x1</td>\n",
       "      <td>0.332440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x2</td>\n",
       "      <td>0.315011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature  importance\n",
       "1     x11    0.352549\n",
       "0      x1    0.332440\n",
       "2      x2    0.315011"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we get the feature importance attributed by the \n",
    "# random forest model (more on this in coming lectures)\n",
    "\n",
    "importance = pd.concat(\n",
    "    [pd.Series(features),\n",
    "     pd.Series(rf.feature_importances_)], axis=1)\n",
    "\n",
    "importance.columns = ['feature', 'importance']\n",
    "importance.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x21</td>\n",
       "      <td>x23</td>\n",
       "      <td>0.895835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature1 feature2      corr\n",
       "4      x21      x23  0.895835"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can now investigate further features within one group.\n",
    "# let's for example select group 3\n",
    "\n",
    "group3 = correlated_groups[2]\n",
    "group3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# we could select the features with less missing data\n",
    "# like this:\n",
    "\n",
    "for feature in list(group3.feature2.unique())+['x21']:\n",
    "    print(X_train[feature].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=39, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(group3.feature2.unique())+['x21']\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "rf.fit(X_train[features].fillna(0), Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x21</td>\n",
       "      <td>0.528087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x23</td>\n",
       "      <td>0.471913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature  importance\n",
       "1     x21    0.528087\n",
       "0     x23    0.471913"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we get the feature importance attributed by the \n",
    "# random forest model (more on this in coming lectures)\n",
    "\n",
    "importance = pd.concat(\n",
    "    [pd.Series(features),\n",
    "     pd.Series(rf.feature_importances_)], axis=1)\n",
    "\n",
    "importance.columns = ['feature', 'importance']\n",
    "importance.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.drop(['x1','x2','x23','x31'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 28)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan Camilo Ceballos\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='warn',\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             random_state=0, solver='saga',\n",
       "                                             tol=0.0001, verbose=0,\n",
       "                                             warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se especifica regresión logística y penalización Lasso (l1), para luego con SelectFromModel\n",
    "# seleccionar en teoría las características cuyos coeficientes no son cero.\n",
    "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='saga',random_state=0))\n",
    "sel_.fit(scaler.transform(X_train.fillna(0)), Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características totales: 28\n",
      "Características seleccionadas: 9\n",
      "Características con coeficientes reducidos a cero: 19\n"
     ]
    }
   ],
   "source": [
    "#Lista de las características seleccionadas\n",
    "selected_feat = X_train.columns[(sel_.get_support())]\n",
    "\n",
    "print('Características totales: {}'.format((X_train.shape[1])))\n",
    "print('Características seleccionadas: {}'.format(len(selected_feat)))\n",
    "print('Características con coeficientes reducidos a cero: {}'.format(np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x5',\n",
       " 'x7',\n",
       " 'x14',\n",
       " 'x15',\n",
       " 'x16',\n",
       " 'x18',\n",
       " 'x19',\n",
       " 'x28',\n",
       " 'x29',\n",
       " 'x8',\n",
       " 'x9',\n",
       " 'x10',\n",
       " 'x11',\n",
       " 'x22',\n",
       " 'x25',\n",
       " 'x26',\n",
       " 'x27',\n",
       " 'x30',\n",
       " 'x32']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se identifica las características eliminadas\n",
    "# we can identify the removed features like this:\n",
    "removed_feats = X_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
    "r=removed_feats.values.tolist()\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 9)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=X_train.drop(r, axis=1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x3', 'x4', 'x6', 'x13', 'x17', 'x20', 'x12', 'x21', 'x24']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seleccionadas=X_train.columns.values.tolist()\n",
    "seleccionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = ['x3','x4','x6','x13','x17','x20']\n",
    "\n",
    "for dum in dummies:\n",
    "    dum_list = \"cat\"+\"_\"+dum\n",
    "    dum_dummies = pd.get_dummies(X_train[dum], prefix=dum_list)\n",
    "    X_train=X_train.join(dum_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.drop(labels=dummies, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo logístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_reglog(X_train_lg, X_test_lg, y_train_lg, y_test_lg):\n",
    "    lista_auc_train = []\n",
    "    lista_auc_test = []\n",
    "    lista_lr = []\n",
    "    lista = [1.0, 1.1, 2.2, 1.3, 1.4, 3.5]\n",
    "    for i in lista:\n",
    "        lr = linear_model.LogisticRegression(solver='liblinear', C = i)\n",
    "        lr.fit(X_train_lg,y_train_lg)\n",
    "        pred_train = lr.predict_proba(X_train_lg)\n",
    "        auc_train = format(roc_auc_score(y_train_lg, pred_train[:,1]))\n",
    "        lista_auc_train.append(auc_train)\n",
    "        \n",
    "        pred_test = lr.predict_proba(X_test_lg)\n",
    "        auc_test = format(roc_auc_score(y_test_lg, pred_test[:,1]))\n",
    "        lista_auc_test.append(auc_test)\n",
    "        \n",
    "        lista_lr.append(lr)\n",
    "        list_auc = list(map(float,lista_auc_test))\n",
    "        \n",
    "    max_index_auc = list_auc.index(max(list_auc))\n",
    "    best_model = lista_lr[max_index_auc]\n",
    "    \n",
    "    print('Best c')\n",
    "    print('c: '+ str(lista[max_index_auc]))\n",
    "    \n",
    "    print('Train set auc')\n",
    "    print(lista_auc_train)\n",
    "        \n",
    "    print('Test set auc')\n",
    "    print(lista_auc_test)\n",
    "    \n",
    "    print('---------------------------------------------------------')\n",
    "    print('Test set')\n",
    "    predictions = best_model.predict(X_test_lg)\n",
    "    print(classification_report(y_test_lg, predictions))\n",
    "    \n",
    "   \n",
    "    dict_lg = {}\n",
    "    pred = best_model.predict_proba(X_test_lg)\n",
    "    auc = max(list_auc)\n",
    "    print('lg roc-auc: {}'.format(auc))\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test_lg, pred[:,1]) \n",
    "    \n",
    "    dict_lg['Modelo'] = best_model\n",
    "    dict_lg['fpr'] = fpr\n",
    "    dict_lg['tpr'] = tpr\n",
    "    dict_lg['auc'] = auc\n",
    "    \n",
    "    \n",
    "    return dict_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 9), (30,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=test.filter(seleccionadas, axis=1)\n",
    "Y_test=test['yL']\n",
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = ['x3','x4','x6','x13','x17','x20']\n",
    "\n",
    "for dum in dummies:\n",
    "    dum_list = \"cat\"+\"_\"+dum\n",
    "    dum_dummies = pd.get_dummies(X_test[dum], prefix=dum_list)\n",
    "    X_test=X_test.join(dum_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test.drop(labels=dummies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best c\n",
      "c: 1.0\n",
      "Train set auc\n",
      "['0.8411764705882353', '0.8455882352941176', '0.861764705882353', '0.85', '0.8514705882352941', '0.8676470588235294']\n",
      "Test set auc\n",
      "['0.645', '0.645', '0.645', '0.645', '0.64', '0.635']\n",
      "---------------------------------------------------------\n",
      "Test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.70      0.58        10\n",
      "         1.0       0.81      0.65      0.72        20\n",
      "\n",
      "    accuracy                           0.67        30\n",
      "   macro avg       0.66      0.68      0.65        30\n",
      "weighted avg       0.71      0.67      0.68        30\n",
      "\n",
      "lg roc-auc: 0.645\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance of algorithm built\n",
    "# using selected features\n",
    "\n",
    "lg_model_ad = run_reglog(X_train.fillna(0),\n",
    "                  X_test.fillna(0),Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
