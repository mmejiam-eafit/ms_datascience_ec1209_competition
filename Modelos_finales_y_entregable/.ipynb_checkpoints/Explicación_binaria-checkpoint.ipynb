{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competencia\n",
    "\n",
    "Mateo, Miguel, Steward y Camilo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General methodology\n",
    "\n",
    "The idea is to use a hybrid method for feature selection: it computes the 'feature importance' derived from the implementation of a Logistic Regression Model (weights of coefficients), adds as well one feature at a time and calculates a new metric based on the new subset of features using the model abovementioned.\n",
    "This recursive feature addition method consists of the following steps:\n",
    "\n",
    "1) Rank the features according to their coefficients derived from a Logistic Regression with ElasticNet regularization.\n",
    "\n",
    "2) Evaluate the Logistic Regression model with only 1 feature, the most important one based on the coefficients from the step 1, and calculate the AUC score for performance.\n",
    "\n",
    "3) Add one feature, the next one most important, to evaluate this new model and calculate the AUC score again.\n",
    "\n",
    "4) If the AUC increases by more than an arbitrarily set threshold, we used 0.001, then that feature is considered important and should be kept. Otherwise, that feature is removed.\n",
    "\n",
    "5) Repeat steps 3 and 4 until all features have been removed (and therefore evaluated) and the improvement in performance assessed.\n",
    "\n",
    "We try this method on 100 different partitions of the data and after that, we finally select only the variables that were pre-selected on at least the 50% of the partitions. We also make sure that the distribution of the estmated Î² gives us a good estimation interval (not crossing 0).\n",
    "\n",
    "When the variables are definitely selected, we estimate another Logistic Regression with ElasticNet regularization with those variables again on other 100 different partitions so that we can have an estimation of the global (AUC) and the specific metric (accuracy) and defined if the proposed model were better than the proposed by other team members.\n",
    "\n",
    "The selected features were x4, x10, x17, x18, x23 and x24."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficient distribution per feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\".\\images\\1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\".\\images\\2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\".\\images\\3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\".\\images\\4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\".\\images\\5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\".\\images\\6.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
